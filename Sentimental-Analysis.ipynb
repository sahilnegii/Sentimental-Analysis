{
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3 (ipykernel)",
            "language": "python"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.7",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        }
    },
    "nbformat_minor": 2,
    "nbformat": 4,
    "cells": [
        {
            "cell_type": "code",
            "source": [
                "import csv\r\n",
                "import json\r\n",
                "import requests\r\n",
                "\r\n",
                "# Replace with your own subscription key and endpoint URL\r\n",
                "subscription_key = 'eff6cd2e2b15427b908a202146a62170'\r\n",
                "endpoint = 'https://assign.cognitiveservices.azure.com/'\r\n",
                "\r\n",
                "# Define the API endpoint for sentiment analysis\r\n",
                "sentiment_url = endpoint + '/text/analytics/v3.0/sentiment'\r\n",
                "\r\n",
                "# Define the path to your Twitter dataset CSV file\r\n",
                "dataset_file = 'twitter_dataset.csv'\r\n",
                "\r\n",
                "# Read the tweets from the CSV file\r\n",
                "tweets = []\r\n",
                "with open(dataset_file, 'r') as csvfile:\r\n",
                "    reader = csv.DictReader(csvfile)\r\n",
                "    for row in reader:\r\n",
                "        tweets.append(row['text'])\r\n",
                "\r\n",
                "# Define the text to be analyzed\r\n",
                "documents = {\"documents\": []}\r\n",
                "for i, tweet in enumerate(tweets):\r\n",
                "    documents[\"documents\"].append({\"id\": str(i+1), \"language\": \"en\", \"text\": tweet})\r\n",
                "\r\n",
                "# Convert the documents dictionary to a JSON string\r\n",
                "documents = json.dumps(documents)\r\n",
                "\r\n",
                "# Define the headers and request parameters\r\n",
                "headers = {\"Ocp-Apim-Subscription-Key\": subscription_key, \"Content-Type\": \"application/json\"}\r\n",
                "params = {}\r\n",
                "\r\n",
                "# Call the Text Analytics API to perform sentiment analysis\r\n",
                "response = requests.post(sentiment_url, headers=headers, params=params, data=documents)\r\n",
                "\r\n",
                "# Parse the JSON response and print the sentiment score for each tweet\r\n",
                "sentiments = response.json()['documents']\r\n",
                "for sentiment in sentiments:\r\n",
                "    tweet_id = int(sentiment['id']) - 1\r\n",
                "    tweet = tweets[tweet_id]\r\n",
                "    score = sentiment['sentimentScores']['positive'] - sentiment['sentimentScores']['negative']\r\n",
                "    print('Tweet: {}\\nSentiment score: {:.2f}\\n'.format(tweet, score))"
            ],
            "metadata": {
                "azdata_cell_guid": "56b091d3-006b-463e-bf81-a8ae970444cd",
                "language": "python"
            },
            "outputs": [],
            "execution_count": null
        }
    ]
}